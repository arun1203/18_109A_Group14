<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_nk374bngp3t7-1>li:before{content:"\0025cb  "}.lst-kix_nk374bngp3t7-0>li:before{content:"\0025cf  "}.lst-kix_nk374bngp3t7-2>li:before{content:"\0025a0  "}.lst-kix_pm4fr1m6nsjn-1>li:before{content:"\0025cb  "}.lst-kix_nk374bngp3t7-3>li:before{content:"\0025cf  "}.lst-kix_pm4fr1m6nsjn-2>li:before{content:"\0025a0  "}.lst-kix_nk374bngp3t7-5>li:before{content:"\0025a0  "}.lst-kix_nk374bngp3t7-4>li:before{content:"\0025cb  "}.lst-kix_nk374bngp3t7-6>li:before{content:"\0025cf  "}.lst-kix_pm4fr1m6nsjn-3>li:before{content:"\0025cf  "}.lst-kix_pm4fr1m6nsjn-5>li:before{content:"\0025a0  "}.lst-kix_pm4fr1m6nsjn-4>li:before{content:"\0025cb  "}.lst-kix_nk374bngp3t7-8>li:before{content:"\0025a0  "}.lst-kix_nk374bngp3t7-7>li:before{content:"\0025cb  "}.lst-kix_kcdft09bxw9i-7>li{counter-increment:lst-ctn-kix_kcdft09bxw9i-7}.lst-kix_kcdft09bxw9i-2>li:before{content:"" counter(lst-ctn-kix_kcdft09bxw9i-2,lower-roman) ". "}.lst-kix_pm4fr1m6nsjn-0>li:before{content:"\0025cf  "}.lst-kix_kcdft09bxw9i-1>li:before{content:"\0025cb  "}.lst-kix_kcdft09bxw9i-0>li:before{content:"" counter(lst-ctn-kix_kcdft09bxw9i-0,decimal) ". "}.lst-kix_kcdft09bxw9i-6>li{counter-increment:lst-ctn-kix_kcdft09bxw9i-6}ul.lst-kix_6b4hzl5h1avu-0{list-style-type:none}.lst-kix_pm4fr1m6nsjn-7>li:before{content:"\0025cb  "}ul.lst-kix_6b4hzl5h1avu-1{list-style-type:none}ul.lst-kix_6b4hzl5h1avu-2{list-style-type:none}ul.lst-kix_6b4hzl5h1avu-3{list-style-type:none}ul.lst-kix_6b4hzl5h1avu-4{list-style-type:none}.lst-kix_pm4fr1m6nsjn-6>li:before{content:"\0025cf  "}ul.lst-kix_6b4hzl5h1avu-5{list-style-type:none}ul.lst-kix_6b4hzl5h1avu-6{list-style-type:none}ul.lst-kix_6b4hzl5h1avu-7{list-style-type:none}ul.lst-kix_6b4hzl5h1avu-8{list-style-type:none}.lst-kix_pm4fr1m6nsjn-8>li:before{content:"\0025a0  "}.lst-kix_ywcbo4t3v11m-0>li:before{content:"\0025cf  "}ul.lst-kix_nk374bngp3t7-5{list-style-type:none}ul.lst-kix_nk374bngp3t7-6{list-style-type:none}ol.lst-kix_kcdft09bxw9i-2.start{counter-reset:lst-ctn-kix_kcdft09bxw9i-2 0}ul.lst-kix_nk374bngp3t7-3{list-style-type:none}ul.lst-kix_nk374bngp3t7-4{list-style-type:none}ol.lst-kix_kcdft09bxw9i-6.start{counter-reset:lst-ctn-kix_kcdft09bxw9i-6 0}ul.lst-kix_nk374bngp3t7-7{list-style-type:none}ul.lst-kix_nk374bngp3t7-8{list-style-type:none}.lst-kix_ywcbo4t3v11m-5>li:before{content:"\0025a0  "}ul.lst-kix_nk374bngp3t7-1{list-style-type:none}ul.lst-kix_nk374bngp3t7-2{list-style-type:none}.lst-kix_ywcbo4t3v11m-4>li:before{content:"\0025cb  "}ul.lst-kix_nk374bngp3t7-0{list-style-type:none}.lst-kix_kcdft09bxw9i-4>li{counter-increment:lst-ctn-kix_kcdft09bxw9i-4}.lst-kix_ywcbo4t3v11m-1>li:before{content:"\0025cb  "}.lst-kix_ywcbo4t3v11m-3>li:before{content:"\0025cf  "}.lst-kix_ywcbo4t3v11m-2>li:before{content:"\0025a0  "}ol.lst-kix_kcdft09bxw9i-7.start{counter-reset:lst-ctn-kix_kcdft09bxw9i-7 0}ul.lst-kix_ccfxqgbnh78z-7{list-style-type:none}ul.lst-kix_ccfxqgbnh78z-6{list-style-type:none}ul.lst-kix_ccfxqgbnh78z-5{list-style-type:none}ul.lst-kix_ccfxqgbnh78z-4{list-style-type:none}ol.lst-kix_kcdft09bxw9i-0.start{counter-reset:lst-ctn-kix_kcdft09bxw9i-0 0}ul.lst-kix_ccfxqgbnh78z-8{list-style-type:none}ol.lst-kix_kcdft09bxw9i-8.start{counter-reset:lst-ctn-kix_kcdft09bxw9i-8 0}ul.lst-kix_ccfxqgbnh78z-3{list-style-type:none}ul.lst-kix_ccfxqgbnh78z-2{list-style-type:none}ul.lst-kix_ccfxqgbnh78z-1{list-style-type:none}ul.lst-kix_ccfxqgbnh78z-0{list-style-type:none}.lst-kix_kcdft09bxw9i-3>li{counter-increment:lst-ctn-kix_kcdft09bxw9i-3}ol.lst-kix_kcdft09bxw9i-3.start{counter-reset:lst-ctn-kix_kcdft09bxw9i-3 0}.lst-kix_kcdft09bxw9i-0>li{counter-increment:lst-ctn-kix_kcdft09bxw9i-0}ol.lst-kix_kcdft09bxw9i-5.start{counter-reset:lst-ctn-kix_kcdft09bxw9i-5 0}.lst-kix_ywcbo4t3v11m-7>li:before{content:"\0025cb  "}.lst-kix_ywcbo4t3v11m-6>li:before{content:"\0025cf  "}.lst-kix_ywcbo4t3v11m-8>li:before{content:"\0025a0  "}ul.lst-kix_pm4fr1m6nsjn-0{list-style-type:none}.lst-kix_ccfxqgbnh78z-4>li:before{content:"\0025cb  "}ul.lst-kix_pm4fr1m6nsjn-1{list-style-type:none}ul.lst-kix_pm4fr1m6nsjn-2{list-style-type:none}ul.lst-kix_pm4fr1m6nsjn-3{list-style-type:none}ul.lst-kix_pm4fr1m6nsjn-4{list-style-type:none}.lst-kix_ccfxqgbnh78z-2>li:before{content:"\0025a0  "}.lst-kix_ccfxqgbnh78z-6>li:before{content:"\0025cf  "}ul.lst-kix_pm4fr1m6nsjn-5{list-style-type:none}ul.lst-kix_pm4fr1m6nsjn-6{list-style-type:none}.lst-kix_ccfxqgbnh78z-1>li:before{content:"\0025cb  "}.lst-kix_ccfxqgbnh78z-5>li:before{content:"\0025a0  "}.lst-kix_6b4hzl5h1avu-8>li:before{content:"\0025a0  "}ul.lst-kix_pm4fr1m6nsjn-7{list-style-type:none}ul.lst-kix_pm4fr1m6nsjn-8{list-style-type:none}.lst-kix_6b4hzl5h1avu-5>li:before{content:"\0025a0  "}.lst-kix_6b4hzl5h1avu-7>li:before{content:"\0025cb  "}.lst-kix_ccfxqgbnh78z-3>li:before{content:"\0025cf  "}.lst-kix_6b4hzl5h1avu-6>li:before{content:"\0025cf  "}ul.lst-kix_ywcbo4t3v11m-0{list-style-type:none}ol.lst-kix_kcdft09bxw9i-0{list-style-type:none}.lst-kix_ccfxqgbnh78z-0>li:before{content:"\0025cf  "}ul.lst-kix_ywcbo4t3v11m-8{list-style-type:none}ol.lst-kix_kcdft09bxw9i-2{list-style-type:none}ul.lst-kix_ywcbo4t3v11m-7{list-style-type:none}ol.lst-kix_kcdft09bxw9i-3{list-style-type:none}ul.lst-kix_ywcbo4t3v11m-6{list-style-type:none}ol.lst-kix_kcdft09bxw9i-4{list-style-type:none}ul.lst-kix_ywcbo4t3v11m-5{list-style-type:none}ol.lst-kix_kcdft09bxw9i-5{list-style-type:none}ul.lst-kix_ywcbo4t3v11m-4{list-style-type:none}ol.lst-kix_kcdft09bxw9i-6{list-style-type:none}ul.lst-kix_ywcbo4t3v11m-3{list-style-type:none}ol.lst-kix_kcdft09bxw9i-7{list-style-type:none}ul.lst-kix_ywcbo4t3v11m-2{list-style-type:none}ol.lst-kix_kcdft09bxw9i-8{list-style-type:none}ul.lst-kix_ywcbo4t3v11m-1{list-style-type:none}.lst-kix_kcdft09bxw9i-3>li:before{content:"" counter(lst-ctn-kix_kcdft09bxw9i-3,decimal) ". "}.lst-kix_kcdft09bxw9i-4>li:before{content:"" counter(lst-ctn-kix_kcdft09bxw9i-4,lower-latin) ". "}.lst-kix_kcdft09bxw9i-6>li:before{content:"" counter(lst-ctn-kix_kcdft09bxw9i-6,decimal) ". "}.lst-kix_kcdft09bxw9i-5>li:before{content:"" counter(lst-ctn-kix_kcdft09bxw9i-5,lower-roman) ". "}.lst-kix_kcdft09bxw9i-7>li:before{content:"" counter(lst-ctn-kix_kcdft09bxw9i-7,lower-latin) ". "}.lst-kix_6b4hzl5h1avu-1>li:before{content:"\0025cb  "}.lst-kix_kcdft09bxw9i-8>li{counter-increment:lst-ctn-kix_kcdft09bxw9i-8}.lst-kix_kcdft09bxw9i-5>li{counter-increment:lst-ctn-kix_kcdft09bxw9i-5}.lst-kix_kcdft09bxw9i-8>li:before{content:"" counter(lst-ctn-kix_kcdft09bxw9i-8,lower-roman) ". "}.lst-kix_6b4hzl5h1avu-0>li:before{content:"\0025cf  "}.lst-kix_6b4hzl5h1avu-4>li:before{content:"\0025cb  "}.lst-kix_ccfxqgbnh78z-8>li:before{content:"\0025a0  "}.lst-kix_6b4hzl5h1avu-3>li:before{content:"\0025cf  "}ul.lst-kix_kcdft09bxw9i-1{list-style-type:none}.lst-kix_kcdft09bxw9i-2>li{counter-increment:lst-ctn-kix_kcdft09bxw9i-2}.lst-kix_ccfxqgbnh78z-7>li:before{content:"\0025cb  "}.lst-kix_6b4hzl5h1avu-2>li:before{content:"\0025a0  "}ol.lst-kix_kcdft09bxw9i-4.start{counter-reset:lst-ctn-kix_kcdft09bxw9i-4 0}ol{margin:0;padding:0}table td,table th{padding:0}.c17{margin-left:58pt;padding-top:11pt;padding-left:0pt;padding-bottom:10pt;line-height:1.15;orphans:2;widows:2;text-align:left;margin-right:22pt}.c23{margin-left:58pt;padding-top:11pt;padding-left:0pt;padding-bottom:0pt;line-height:1.4285714285714286;orphans:2;widows:2;text-align:left;margin-right:22pt}.c9{color:#4a86e8;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c33{padding-top:11pt;padding-bottom:0pt;line-height:1.4285714285714286;orphans:2;widows:2;text-align:left;margin-right:22pt}.c13{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c6{color:#333333;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c12{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c28{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:italic}.c22{padding-top:11pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c3{background-color:#ffffff;-webkit-text-decoration-skip:none;color:#333333;text-decoration:underline;text-decoration-skip-ink:none;font-size:10pt}.c20{padding-top:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c7{padding-top:0pt;padding-bottom:5pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c14{background-color:#ffffff;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline;text-decoration-skip-ink:none;font-size:10pt}.c18{padding-top:0pt;padding-bottom:5pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c36{padding-top:0pt;padding-bottom:16pt;line-height:1.15;page-break-after:avoid;text-align:left}.c31{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;text-align:left}.c21{color:#4a86e8;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c5{font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c25{-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline;text-decoration-skip-ink:none}.c29{padding-top:14pt;padding-bottom:4pt;line-height:1.15;text-align:left}.c4{background-color:#ffffff;font-size:10pt;color:#333333}.c34{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c11{font-size:10pt;color:#333333;font-weight:700}.c0{color:inherit;text-decoration:inherit}.c15{background-color:#ffffff;font-size:10pt}.c32{color:#000000;font-size:26pt}.c16{font-size:10pt;font-weight:700}.c24{padding:0;margin:0}.c27{color:#666666;font-size:15pt}.c10{margin-left:36pt;padding-left:0pt}.c8{height:11pt}.c26{font-weight:700}.c35{background-color:#ffffff}.c19{font-size:10pt}.c30{font-style:italic}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c34"><p class="c31 title" id="h.84eef5ces9ei"><span class="c5 c32">Lending Club Project</span></p><p class="c36 subtitle" id="h.26mkqxj0u52g"><span class="c5 c27">Group 14: Milestone 3 (Revised project statement and EDA)</span></p><p class="c1 c8"><span class="c2"></span></p><p class="c7"><span class="c9">Project background</span></p><p class="c18"><span class="c2">LendingClub is a peer-to-peer lending network that launched in 2006. It provides a marketplace that allows potential borrowers to apply for loans. Investors can review these applications and decide how much they are willing to fund - either manually or through an automated strategy. To facilitate this evaluation, LendingClub provides data on the borrower that can be used to determine investment decisions. </span></p><p class="c18"><span class="c19">The first part of the project is to build a model that can be used to inform an investment strategy, which could be used by a LendingClub investor. The research question we have proposed for this part is: </span><span class="c19 c30">Given a loan application, our model will predict whether the applicant will &#39;pay-off&#39; or &#39;charge-off&#39; the loan.</span></p><p class="c18"><span class="c19">The second part of the project is to investigate potential issues of discrimination. LendingClub requires that its investors commit to not violating borrower discrimination laws. Thus, it is not permitted to use characteristics such as race, sex, religion etc when deciding whether or not to invest in loans. Although the information reported does not contain demographic information that would allow for direct consideration of these factors, there are other variables that could be used to infer an applicant&rsquo;s social characteristics, such as their location (correlating with race) or years of employment (correlating with age). &nbsp;</span><span class="c19">Our proposed approach to this second part of the project is based on a literature review and explained further below. </span></p><p class="c7 c8"><span class="c2"></span></p><p class="c7"><span class="c9">Description of the data and initial cleaning</span></p><p class="c18"><span class="c2">LendingClub provides two datasets: Loan data (for all loans issued) and Declined loan data (loan applications that did not meet LendingClub&rsquo;s credit underwriting policy.</span></p><p class="c18"><span class="c2">The Loan data covers the period from 2007 to Q2 2018. It contains around 150 variables, details of which are provided in a data dictionary. </span></p><p class="c18"><span class="c2">The Declined loan data covers the same period; however, it only contains nine predictors and refers to applications that do not make it onto the LendingClub platform. This data is therefore not considered relevant to the research question, since investors would not consider these applicants in their strategies. </span></p><p class="c22"><span class="c2">We have elected to focus on the data for 2016 and 2017 for the purposes of training the model. This is because:</span></p><ul class="c24 lst-kix_6b4hzl5h1avu-0 start"><li class="c23"><span class="c2">The variables included in the datasets have changed over time, meaning that features in the more recent datasets are not necessarily available in the older datasets.</span></li><li class="c23"><span class="c2">Since the model will be used to inform an investment strategy going forwards, the most relevant data are from recent years.</span></li></ul><p class="c33"><span class="c2">The dataset is reasonably clean and we were able to gap-fill most of the missing data with sensible values and minimise dropping of rows. This suggests that there are no issues of potential biases due to dropping rows with missing data. &nbsp;In summary, the following data cleaning operations were carried out:</span></p><ul class="c24 lst-kix_ywcbo4t3v11m-0 start"><li class="c17"><span class="c16">Removal of columns to prevent data leakage,</span><span class="c19">&nbsp;i.e. removing those that contained information that would only become available after the loan has been issued. &nbsp;Keeping such variables would lead to artificially good model predictions, and hence it is important to remove them. We contacted the Lending Club help desk in order to indicate which columns were updated monthly and which were available at the time of application. Only variables that are available at the time of the loan application were kept. Examples of removed columns include: </span><span class="c15">recoveries, collection_recovery_fee, total_pymnt, columns starting with next_ or last_ etc.</span></li><li class="c17"><span class="c16">Removal of uninformative columns</span><span class="c19">, e.g. those that contained no data or single values (e.g. </span><span class="c15">id, member_id, url)</span></li><li class="c17"><span class="c16">Filling missing values, </span><span class="c2">using sensible assumptions. For instance, missing data was typically filled with zeros unless this did not make sense (for instance, all of the mths_since... variables have many missing values. We cannot replace NaNs with 0&#39;s since this would suggest that there had been a recent occurrence. Therefore these are re-coded as binary variables with 0 indicating no occurrence and 1 indicating an occurrence).</span></li><li class="c17"><span class="c16">Recoding the data, </span><span class="c19">for example, converting employment length to numeric, recoding binary variables as 0, 1.</span></li></ul><p class="c7"><span class="c19">The</span><span class="c16">&nbsp;</span><span class="c16 c30">loan status</span><span class="c16">,</span><span class="c19">&nbsp;is the target predictor for our current research question. &nbsp;This includes 7 statuses: current, fully paid, charged off, late (31 - 120 days), late (16 - 30 days), in grace period and default. &nbsp;Due to the need to ensure that we compare on a like-for-like basis, we only consider loans that have completed their full life cycle (i.e. loan status of </span><span class="c16">&ldquo;fully paid&rdquo; or &ldquo;charged off&rdquo;)</span><span class="c19">, since the status of current loans may change over time.</span></p><p class="c7 c8"><span class="c2"></span></p><p class="c7"><span class="c9">Summary of noteworthy findings from the EDA</span></p><p class="c7"><span class="c2">As described above, we are focusing on the dataset from 2016 and 2017. That dataset has about 90 predictors and 334,000 observations. The ratio of &ldquo;Fully paid&rdquo; to &ldquo;Charged off&rdquo; loans in the original set is about 3:1 which makes it somewhat imbalanced. We will consider that by balancing the data for the modelling process. </span></p><p class="c7"><span class="c19">For the purposes of EDA, however, we kept the original dataset. We ran a correlation analysis to see which predictors correlate and we also ran several modelling algorithms (LassoCV, Decision Tree and Random Forest) that would help us find the most significant predictors in the dataset. Below are some examples of the most important predictors that had a higher impact on the target variable </span><span class="c16">loan status</span><span class="c2">:</span></p><ul class="c24 lst-kix_ccfxqgbnh78z-0 start"><li class="c1 c10"><span class="c2">Interest Rate</span></li><li class="c1 c10"><span class="c2">Sub Grade (a rating that Lending Club assigned to the loan)</span></li><li class="c1 c10"><span class="c2">Average Current Balance (of all accounts)</span></li><li class="c1 c10"><span class="c2">FiCo score (the borrower&rsquo;s credit score)</span></li><li class="c1 c10"><span class="c2">Dti (the debt to income ratio)</span></li><li class="c1 c10"><span class="c2">Installment (the monthly payment owed by the borrower if the loan originates)</span></li><li class="c1 c10"><span class="c2">Employment length (in years)</span></li><li class="c1 c10"><span class="c2">Term (36 or 60 months)</span></li><li class="c1 c10"><span class="c2">Revolving line utilization rate (the amount of credit the borrower is using relative to all available revolving credit)</span></li><li class="c1 c10"><span class="c2">Loan amount</span></li><li class="c1 c10"><span class="c2">Annual income</span></li><li class="c1 c10"><span class="c2">Home ownership</span></li></ul><h3 class="c29" id="h.mrwhsi2hxpy5"><span class="c12">Loan amount</span></h3><p class="c7"><span class="c2">When we look at the distribution of the loan amount, it shows a preference for requesting values in $5k steps, such as $5k, $10k, $15k, $20k, $35k etc. Most loans are relatively smaller amounts: 50% of all loans are below $12,500 and 75% below $20,000</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 477.00px; height: 257.50px;"><img alt="" src="images/image9.png" style="width: 477.00px; height: 257.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 118.50px; height: 85.39px;"><img alt="" src="images/image6.png" style="width: 118.50px; height: 85.39px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c29" id="h.76p2dmgzncca"><span class="c12">Loan risk (i.e. grades/ratings and interest rates)</span></h3><p class="c7"><span class="c2">When looking at the loan risk (expressed as sub grades), the grades go from A1 (highest/best) to G5 (lowest/worst). We can see a trend that looks like smaller loan amounts are usually rated as a lower risk and larger loans are usually rated riskier, which makes sense.</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 535.00px; height: 261.50px;"><img alt="" src="images/image7.png" style="width: 535.00px; height: 261.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">As far as the default by grade goes, it seems that grades A and B are fairly &ldquo;safe&rdquo; because the majority of loans in these classes are paid off; however, anything lower than a D (i.e. riskier grade) has a risk of 63-77% of defaulting.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 382.50px; height: 83.87px;"><img alt="" src="images/image1.png" style="width: 382.50px; height: 83.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">Interest rates are higher for lower sub grades, which also makes sense, since the interest rate reflects a measurement of risk and so does the sub grade.</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 440.50px; height: 265.03px;"><img alt="" src="images/image3.png" style="width: 440.50px; height: 265.03px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c2">This also seems to be confirmed when looking at the rate of defaulted loans by interest rate. The higher the interest rate, the more likely that a loan is going to default (see below).</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 463.50px; height: 313.03px;"><img alt="" src="images/image8.png" style="width: 463.50px; height: 313.03px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c29" id="h.drg6a7f2gv2"><span class="c12">Loans by States</span></h3><p class="c7"><span class="c2">We can also show that almost 40% of all loans were made in only the top four States: CA, TX, NY and FL.</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 367.50px; height: 114.94px;"><img alt="" src="images/image4.png" style="width: 367.50px; height: 114.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">When looking at the average annual incomes, three of these States (CA, NY and TX) are in the top 10, but FL is on rank 27. This leaves the question as to why there have been so many loans in FL?</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 273.42px; height: 98.50px;"><img alt="" src="images/image10.png" style="width: 273.42px; height: 98.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">&nbsp;</span></p><p class="c1"><span class="c2">Since 40% of all loans were made in the top four States, we would naturally expect those to have the highest absolute numbers of defaults too. However, we can also look at which States have a higher default rate than the national average of 23.64%. This shows that especially some States in the South like AR, LA, MS and AL are at the top of the list.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 231.99px; height: 128.50px;"><img alt="" src="images/image2.png" style="width: 231.99px; height: 128.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c29" id="h.oipz2xf9qdx2"><span class="c12">Loan purpose</span></h3><p class="c1"><span class="c19">Another interesting aspect we looked at was the defaulted loans by loan purpose and/or by loan grade. We know that our &quot;base charged off rate&quot;, meaning the % of all charged off loans over all loans made in 2016-2017 is 23.64%. This means all loan purposes that show a higher percentage in the table below, are probably at a higher risk than average to default. In this case that is </span><span class="c13">dept_collection, medical, moving, renewable_energy, small_business and other.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 267.71px; height: 279.50px;"><img alt="" src="images/image5.png" style="width: 267.71px; height: 279.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7 c8"><span class="c16 c21"></span></p><p class="c7"><span class="c9">Literature review</span></p><p class="c1"><span class="c2">To inform our approach to the second part of the research question on fairness, we conducted a literature review. The findings are outlined below.</span></p><p class="c1 c8"><span class="c2"></span></p><p class="c1 c8"><span class="c6"></span></p><p class="c1"><span class="c11">AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias</span></p><p class="c1 c8"><span class="c2"></span></p><p class="c1"><span class="c11">Citation:</span><span class="c4">&nbsp;</span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DBellamy%252C%2BR%2BK%2BE&amp;sa=D&amp;ust=1544317229297000">Rachel K. E. Bellamy</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DDey%252C%2BK&amp;sa=D&amp;ust=1544317229298000">Kuntal Dey</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DHind%252C%2BM&amp;sa=D&amp;ust=1544317229298000">Michael Hind</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DHoffman%252C%2BS%2BC&amp;sa=D&amp;ust=1544317229299000">Samuel C. Hoffman</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DHoude%252C%2BS&amp;sa=D&amp;ust=1544317229299000">Stephanie Houde</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DKannan%252C%2BK&amp;sa=D&amp;ust=1544317229299000">Kalapriya Kannan</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DLohia%252C%2BP&amp;sa=D&amp;ust=1544317229300000">Pranay Lohia</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DMartino%252C%2BJ&amp;sa=D&amp;ust=1544317229300000">Jacquelyn Martino</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DMehta%252C%2BS&amp;sa=D&amp;ust=1544317229301000">Sameep Mehta</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DMojsilovic%252C%2BA&amp;sa=D&amp;ust=1544317229301000">Aleksandra Mojsilovic</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DNagar%252C%2BS&amp;sa=D&amp;ust=1544317229301000">Seema Nagar</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DRamamurthy%252C%2BK%2BN&amp;sa=D&amp;ust=1544317229302000">Karthikeyan Natesan Ramamurthy</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DRichards%252C%2BJ&amp;sa=D&amp;ust=1544317229302000">John Richards</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DSaha%252C%2BD&amp;sa=D&amp;ust=1544317229302000">Diptikalyan Saha</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DSattigeri%252C%2BP&amp;sa=D&amp;ust=1544317229303000">Prasanna Sattigeri</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DSingh%252C%2BM&amp;sa=D&amp;ust=1544317229303000">Moninder Singh</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DVarshney%252C%2BK%2BR&amp;sa=D&amp;ust=1544317229304000">Kush R. Varshney</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DZhang%252C%2BY&amp;sa=D&amp;ust=1544317229304000">Yunfeng Zhang</a></span><span class="c4">. October 3rd 2018. </span><span class="c16 c25"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/abs/1810.01943&amp;sa=D&amp;ust=1544317229304000">https://arxiv.org/abs/1810.01943</a></span></p><p class="c1"><span class="c11">What: </span><span class="c4">This paper introduces a new open source Python toolkit for algorithmic fairness</span></p><p class="c1"><span class="c11">How: </span><span class="c4">The main objectives of this toolkit are to help </span><span class="c15">facilitate the transition of fairness research algorithms </span><span class="c15">to use in an industrial setting, and to provide a common framework for fairness researchers to share and evaluate algorithms.</span><span class="c15 c26">&nbsp;</span><span class="c15">The library contains at present 10 bias mitigation algorithms, and support a number of fairness metrics that can help mitigate bias in dataset and models. </span></p><p class="c1 c8"><span class="c6"></span></p><p class="c20 c8"><span class="c13"></span></p><p class="c20"><span class="c13">Algorithmic decision making and the cost of fairness</span></p><p class="c1"><span class="c11">Citation: </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DCorbett-Davies%252C%2BS&amp;sa=D&amp;ust=1544317229307000">Sam Corbett-Davies</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DPierson%252C%2BE&amp;sa=D&amp;ust=1544317229307000">Emma Pierson</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DFeller%252C%2BA&amp;sa=D&amp;ust=1544317229307000">Avi Feller</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DGoel%252C%2BS&amp;sa=D&amp;ust=1544317229308000">Sharad Goel</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DHuq%252C%2BA&amp;sa=D&amp;ust=1544317229308000">Aziz Huq</a></span><span class="c4">, June 10th 2017 </span><span class="c14"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/abs/1701.08230&amp;sa=D&amp;ust=1544317229308000">https://arxiv.org/abs/1701.08230</a></span></p><p class="c1"><span class="c11">What: </span><span class="c4">Algorithms are regularly used to decide whether defendants awaiting trial are too dangerous to be released. In some cases, black defendants are substantially more likely than white defendants to be incorrectly classified as high risk. To mitigate such disparities, several techniques have recently been proposed to achieve algorithmic fairness.</span></p><p class="c1"><span class="c11">How:</span><span class="c4">&nbsp;In this paper the authors reformulate algorithmic fairness as constrained optimization: the objective is to maximize public safety while satisfying formal fairness constraints designed to reduce racial disparities.</span></p><p class="c1"><span class="c11">Conclusion: </span><span class="c5 c4">By analyzing data from Broward County, the authors find that optimizing for public safety yields stark racial disparities; conversely, satisfying past fairness definitions means releasing more high-risk defendants, adversely affecting public safety. And algorithms have the potential to improve the efficiency and equity of decisions, but their design and application raise complex questions for researchers and policymakers.</span></p><p class="c1 c8"><span class="c6"></span></p><p class="c8 c20"><span class="c13"></span></p><p class="c20"><span class="c13">Decoupled classifiers for fair and efficient machine learning</span></p><p class="c1"><span class="c11">Citation:</span><span class="c4">&nbsp;</span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DDwork%252C%2BC&amp;sa=D&amp;ust=1544317229311000">Cynthia Dwork</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DImmorlica%252C%2BN&amp;sa=D&amp;ust=1544317229311000">Nicole Immorlica</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DKalai%252C%2BA%2BT&amp;sa=D&amp;ust=1544317229311000">Adam Tauman Kalai</a></span><span class="c4">, </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://arxiv.org/search/cs?searchtype%3Dauthor%26query%3DLeiserson%252C%2BM&amp;sa=D&amp;ust=1544317229312000">Max Leiserson</a></span><span class="c4">, July 21, 2017 </span><span class="c14">https://arxiv.org/pdf/1707.06613v1.pdf</span></p><p class="c1"><span class="c11">What: </span><span class="c4">The paper considers how to use a sensitive attribute such as gender or race to maximize fairness and accuracy, assuming it is legal and ethical.</span><span class="c6">&nbsp;</span></p><p class="c1"><span class="c11">How: </span><span class="c4">In this paper they explore decoupled classification systems, in which a separate classifier is trained on each group.</span><span class="c6">&nbsp;</span></p><p class="c1"><span class="c11">Conclusion:</span><span class="c4">&nbsp;Experiments demonstrate that decoupling can reduce the loss on some datasets for some potentially sensitive features</span></p><p class="c1 c8"><span class="c6"></span></p><p class="c1 c8"><span class="c6"></span></p><p class="c1 c8"><span class="c6"></span></p><p class="c1"><span class="c6">Evidence and Actions on Mortgage Market Disparities: Research, Fair lending Enforcement and Consumer Protection</span></p><p class="c1 c8"><span class="c6"></span></p><p class="c1"><span class="c11">Citation: </span><span class="c4">Marsha J. Courchane &amp; Stephen L. Ross, 2018. &quot;</span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://ideas.repec.org/p/hka/wpaper/2018-052.html&amp;sa=D&amp;ust=1544317229314000">Evidence and Actions on Mortgage Market Disparities: Research, Fair Lending Enforcement and Consumer Protection</a></span><span class="c4">,&quot; </span><span class="c3"><a class="c0" href="https://www.google.com/url?q=https://ideas.repec.org/s/hka/wpaper.html&amp;sa=D&amp;ust=1544317229315000">Working Papers</a></span><span class="c4">&nbsp;2018-052, Human Capital and Economic Opportunity Working Group. </span><span class="c14">http://web2.uconn.edu/economics/working/2018-14.pdf</span></p><p class="c1"><span class="c11">What:</span><span class="c4">&nbsp;The authors present overviews of the research on discrimination in mortgage underwriting and pricing, the experiences of minority borrowers prior to and during the financial crisis, as well as discuss the history of legal cases alleging disparate treatment of minority borrowers.</span></p><p class="c1"><span class="c11">How:</span><span class="c4">&nbsp;By using the existing research and legal discussions as a background, they discuss and examine mortgage regulations as well as recent developments in the FinTech industry including machine learning.</span></p><p class="c1"><span class="c11">Conclusion: </span><span class="c4">The empirical evidence is clear that unexplained racial and ethnic differences in both mortgage underwriting and prices are relatively small when looking within lender and controlling for product attributes. Yet, race and ethnicity appear to play a role in determining mortgage market outcomes in the U.S. economy. The authors believe many factors, including information, attachment to financial markets, pre- application assistance levels and even shopping behavior contributed to the long-standing failure of prime qualified minority borrowers to access the conventional, conforming loan market.</span></p><p class="c1 c8"><span class="c2"></span></p><p class="c1 c8"><span class="c2"></span></p><p class="c1"><span class="c13">Peer-to-peer lending and bias in crowd decision-making</span></p><p class="c1"><span class="c11">Citation: </span><span class="c4">Singh P, Uparna J, Karampourniotis P, Horvat E-A, Szymanski B, Korniss G, et al. (2018) Peer-to-peer lending and bias in crowd decision-making. PLoS ONE 13(3): e0193007. </span><span class="c14"><a class="c0" href="https://www.google.com/url?q=https://doi.org/10.1371/journal.pone.0193007&amp;sa=D&amp;ust=1544317229317000">https://doi.org/10.1371/journal.pone.0193007</a></span></p><p class="c1 c8"><span class="c6"></span></p><p class="c1"><span class="c11">What:</span><span class="c5 c4">&nbsp;The authors investigate the &ldquo;flat-world&rdquo; hypothesis, which is the idea that globalization eventually leads to economic equality by analyzing crowdfinancing data, to see if it creates opportunities for the world&rsquo;s poor. </span></p><p class="c1"><span class="c11">How:</span><span class="c4">The authors analyzed 600 000 peer-to-peer loans made to individual lenders in more than 220 countries to borrowers in 80 countries. They used regression analysis to predict bias in country-pair transactions based on variables such as GDP, geographical distance and so forth, checked for deviations of the co-country network of loans and checked the potential susceptibility of the network to shocks that could change the system&rsquo;s ability potential for flatness.</span></p><p class="c1"><span class="c11">Conclusion: </span><span class="c5 c4">The authors found continued and increased bias in an inter-country, peer-to-peer crowdfinancing network. The biases are reinforced and made stronger by the rapid growth of the platform itself (&ldquo;rich gets richer&rdquo; effect). However, by removing a few high-volume lenders or high-transaction links could cause the network&rsquo;s flatness to increase significantly. In this way, the bias is directly linked with the dominance of a few big players.</span></p><p class="c1 c8"><span class="c2"></span></p><p class="c7 c8"><span class="c21 c16"></span></p><p class="c7"><span class="c9">Conclusions from the EDA and literature review</span></p><p class="c1"><span class="c2">The EDA and literature review indicated that we need to take some additional steps to pre-process the data and construct useful models. </span></p><p class="c1 c8"><span class="c2"></span></p><p class="c1"><span class="c19">Firstly, the classes are imbalanced, with the majority (around three-quarters) of loans being fully paid. Having imbalanced data may give a false impression of the performance of the model, and can negatively affect the performance of some learning algorithms such as logistic regression. </span><span class="c13">We will therefore balance the training data by resampling to achieve a 50:50 split between the target classes. &nbsp;</span></p><p class="c1 c8"><span class="c2"></span></p><p class="c1"><span class="c19">Secondly, the cost of a false positive is high in this particular example - i.e. the cost of a defaut is much greater (where the investor can potentially lose all the invested money), compared to the potential upside of making a successful loan (where the investor will gain the interest rate on repayments). This means that accuracy is not the best metric and we want to focus on limiting the number of false positives as much as possible. </span><span class="c16">Therefore, we will use a selection of metrics other than accuracy. These include: precision, recall, F1_score, and AUC (area under the ROC curve). </span><span class="c19">These are explained further when developing the functions in the modelling approach. </span></p><p class="c1 c8"><span class="c28 c19"></span></p><p class="c1"><span class="c2">Lastly we plan to explore various metrics of fairness to test whether the outcomes of the algorithms lead to different results for protected vs unprotected classes. These metrics include equal opportunity, predictive equality and statistical parity. Again, these are explained in more detail in the modelling approach. We have chosen to implement these metrics as direct calculations. </span></p><p class="c1 c8"><span class="c2"></span></p><p class="c1"><span class="c19">However, there are limitations in such metrics. For instance, they should be used in allocation of risk assessment problems with well-defined protected attributes, in which one would like to have some sort of statistical or mathematical notion of sameness. We will need to ensure that we do not create biases where there are none, or just by assuming different groups are reflected differently in the dataset. </span></p><p class="c1 c8"><span class="c5 c4"></span></p><p class="c7 c8"><span class="c21 c16"></span></p><p class="c7"><span class="c9">Baseline model</span></p><p class="c1"><span class="c19">As mentioned above, the dataset will be rebalanced to contain balanced classes. For the most simple baseline model, if a model simply assumes that all loans are fully paid, it will achieve 50% precision. This is our initial baseline. </span></p><p class="c1 c8"><span class="c2"></span></p></body></html>